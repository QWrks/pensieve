<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Logical Open Sorts (LOS) • pensieve</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><!-- docsearch --><script src="../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous">
<link href="../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="Logical Open Sorts (LOS)">
<meta property="og:description" content="">
<meta property="og:image" content="http://www.maxheld.de/pensieve/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-48816137-1"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-48816137-1');
</script>
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">pensieve</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="Unreleased version">0.0.0.9022</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/introduction.html">Introduction</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Design</li>
    <li>
      <a href="../articles/methodology.html">Methodology</a>
    </li>
    <li>
      <a href="../articles/items.html">Items</a>
    </li>
    <li>
      <a href="../articles/grid.html">Grid</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">New Approaches</li>
    <li>
      <a href="../articles/pairwise.html">Pairwise</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/maxheld83/pensieve">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Logical Open Sorts (LOS)</h1>
                        <h4 class="author">Maximilian Held</h4>
                        <h4 class="author">Verena Kasztantowicz</h4>
            
            <h4 class="date">2020-01-20</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/maxheld83/pensieve/blob/master/vignettes/q-cat.Rmd"><code>vignettes/q-cat.Rmd</code></a></small>
      <div class="hidden name"><code>q-cat.Rmd</code></div>

    </div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      <p>In Q methodology, subjectivity is measured in <em>closed sorts</em> along one or several <em>given</em> dimensions, such as a condition of instruction shared with all participants. Other methods, such as <a href="https://en.wikipedia.org/wiki/Repertory_grid">Repertory Grid Technique</a> (RGT) and several <em>open sorting</em> techniques allow each participant to define her own dimensions, though these approaches do not share the tenets of operant subjectivity, such as an ipsative measurement and Q-mode extraction. We here describe a data gathering procedure and experimental analysis to unite these two features, to measure a operant subjectivity with <em>open sorts</em>, starting with logical assignments. We invite participants to come up with their own, dichotomous categories and ask them to classify the full Q-Set accordingly. The resultant logical table is summarized into a per-person measure of categorical item similarity, in turn transformed into a person-by-person correlation matrix. We then extract higher-level principal components (PCA) in a stepwise residual process, and calculate the respective (rotated) component scores, yielding ideal-typical, shared ways of categorizing the Q-Set. These categorical viewpoints are then subjected to a nested, low-level PCA to allow a substantive abduction of just <em>what</em> those categories might be. Using real-world data gathered for this purpose, we show that results from the suggested procedure can be meaningfully interpreted as operant subjectivity with open dimensionality. We also present software for the R statistics framework to run the analysis. To spontaneously and ideosyncratically categorise things and ideas encountered in the world, is perhaps a definiting operation of the human mind. Here too, using the right approach, we can distill shared, categorical viewpoints on these items, extending the scientific study of human subjectivity to new formats and realms.</p>
    </div>
    
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<blockquote>
<p>“The factors are likewise natural, representing actual <em>categories of thinking</em> that are operant with respect to the issues under consideration.”</p>
<p>– Steven Brown <span class="citation">(1980: 70, emphasis added)</span></p>
</blockquote>
<!-- TODO must add more background, literature and motivation here -->
<p>In this procedure, participants sort items according to their own, “first-person”, arbitrary categories. <!-- TODO add citation for first-person --> These categories are:</p>
<ul>
<li>
<strong>operant</strong>, because they arise <em>spontaneously</em> as participants engage the items,</li>
<li>
<strong>inductive</strong>, because participants describe their own, <em>open-ended</em> categories, which can be neither correct, nor incorrect,</li>
<li>
<strong>ipsatively</strong> assigned, because categories are originally defined as <em>similarity</em> between categories.</li>
</ul>
<p>In contrast to other sorting techniques, which require a <em>single</em> set of mutually exclusive, and comprehensively exhaustive (“MECE”) categories as a disjoint set vis-a-vis the items <span class="citation">(Coxon 1999, 127:3)</span>, <code>Q-Cat</code> <em>encourages</em> overlapping <em>multiple</em> categories, each of which is merely <em>logically</em> (<code>TRUE</code>, <code>FALSE</code>) assigned to each item. This complicates the analysis, but avoids imposing a pre-supposed structure of categorical subjectivity on participants.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<!-- - not clear what this is: Multiple Sorting Procedure [@barnett-2004] -->
</div>
<div id="sorting-procedure" class="section level1">
<h1 class="hasAnchor">
<a href="#sorting-procedure" class="anchor"></a>Sorting Procedure</h1>
<!--TODO VK: do these files this still exist, and are they ehlpful to explain the procedure? 
[](Verena/Documents/GoogleDrive/komki/pics/qpic13.png)
[](Verena/Documents/GoogleDrive/komki/pics/qpic9.png)
[](Verena/Documents/GoogleDrive/komki/pics/qpic10.png)
[](Verena/Documents/GoogleDrive/komki/pics/qpic11.png)
[](Verena/Documents/GoogleDrive/komki/pics/qpic12.png)
[](Verena/Documents/GoogleDrive/komki/pics/qpic14.png)
-->
<p>As in a traditional Q-sort, the LOS procedure requires items printed on paper cards. The same criteria for good items hold. <!-- TODO cite section on good items; mention differences --> For this study, the 35 items covered language games, such as the following two examples:</p>
<blockquote>
<p><strong>Language of Bees</strong><br><em>Bee-german: ‘Summ, summ, summ.’<br>
Bee-english: ‘Samm, Samm, Samm.’<br>
Bee-french: ‘Summe, summe, summe.’<br>
Bee-finnish: ‘Suomi, suomi, suomi’</em></p>
</blockquote>
<blockquote>
<p><strong>Let’s eat Grandpa</strong><br><em>Let’s eat grandpa.<br>
Let’s eat, grandpa.<br>
Commas - They save lives!</em></p>
</blockquote>
<p>As in Q, personal administration of the sorts with one-on-one interviews are recommended to get a deeper sense about what the participants are thinking and to avoid influences between them, but online administration is also conceivable.</p>
<p>If the participants are not familiar with the items, you should plan enough time to let them read all the items carefully or to listen to an audio version of, as we have done with the children in this study to make sure they have experienced the whole text. Sometimes you can gather some interesting spontaneous reactions here (laughter, incomprehension or refusal), to whom you could come back later in the interview.</p>
<p>As a starting question, we asked the participants to take two items, which seems similar to them (in any aspect) and put them to the side. We asked them to describe in what way the texts are similar and what feature they share. We then noted this category description in a paper table, sorted by an category index (say, from <code>A</code> to <code>Z</code>). Starting out with pairs of similar items, naturally, increases the minimum number of <em>shared</em> categories: this procedure will never yield a category which applies only to a <em>single</em> item. This “bias” is defensible, because it flows from what we want to measure: categorical <em>similarity</em> between the items. <!-- must explain more clearly, that this degree of minimal similary is, in fact, by design --> A single-item category produces no additional information in this regard, and it is unclear how a category with a membership of one would be meaningful.</p>
<p>After each paired comparison, we invited the participating children to find <em>more</em> items, for which the category would apply, putting them to one side of the table. Once all items have been considered for the category in question, the index of that category (say, <code>C</code>) is noted on all cards, for which the category applied. All cards are then mixed again, placed in the center of the table, and the process begins again, with a new pair of similar items.</p>
<div class="figure">
<img src="q-cat-stage-0.jpg" alt="Participant considers all items." width="100%"><p class="caption">
Participant considers all items.
</p>
</div>
<div class="figure">
<img src="q-cat-stage-1.jpg" alt="Participant chooses two similar items, names category." width="100%"><p class="caption">
Participant chooses two similar items, names category.
</p>
</div>
<div class="figure">
<img src="q-cat-stage-2.jpg" alt="Participant applies categories to all items." width="100%"><p class="caption">
Participant applies categories to all items.
</p>
</div>
<div class="figure">
<img src="q-cat-stage-3.jpg" alt="All items are categorized as TRUE or FALSE." width="100%"><p class="caption">
All items are categorized as TRUE or FALSE.
</p>
</div>
<p>Ensuring that any one category is assessed for <em>all</em> items can be mentally taxing for the participants, but is essential for the downstream analysis. We also tried an alternative procedure, where participants first define all categories, and then check all items for each of the categories. This can sometimes be a little faster, but the categories cannot be as easily changed, and the ipsative nature of the assessment may be lost. Whatever the order, the tedium of assessing <em>all</em> categories on <em>all</em> items remains. This tiring step in LOS is an unavoidable disadvantage of the approach, and compares unfavorably to Q-sorts, which participants often enjoy completing.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<p>The participating children sometimes had a hard time explaining a category, mixing several characteristics or simply describing items as “strange”. This is to be expected, perhaps in any age group, because spontaneous categorisations are rarely well-defined. If participants so choose, they can revise their category descriptions at any point, but these can also remain imperfect. LOS is an attempt to measure categorical similarity between the items, and as such, the categories may well <em>be</em> vague and ill-defined – that may be just the operant subjectivity. Accordingly, the category descriptions do not actually figure in the downstream analysis, they merely serve in the final interpretation to make sense of the extracted factors of categorical similarity.</p>
</div>
<div id="data-storage" class="section level1">
<h1 class="hasAnchor">
<a href="#data-storage" class="anchor"></a>Data Storage</h1>
<!-- TODO this would appear to be wrong; ass in canonical form is a LIST of matrices, not an array -->
<p>For our example study on categorizations of language games with children and grown-ups, this yields a <em>list</em> of description matrices (one element for each participant, as in table @ref(tab:desc-example)) and a three-dimensional <em>array</em> of assignment matrices (one slice for each participant, as in table @ref(tab:ass-example)).<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span>opts_chunk<span class="op">$</span><span class="kw">set</span>(<span class="dt">eval =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div id="analysis-1-shared-categories-as-surprising-similarity" class="section level2">
<h2 class="hasAnchor">
<a href="#analysis-1-shared-categories-as-surprising-similarity" class="anchor"></a>Analysis 1: Shared Categories as Surprising Similarity</h2>
<p>To analyze <code>Q-Cat</code> data, we must first render the individual categorisations comparable.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> To do that, we first transform the binary assignments into continuous deviations from <em>probable</em> assignments. The probable assignment is the <em>expected value</em> <span class="math inline">\(\mathbb{E}\)</span> for some item draw, which is, intuitively, the probability-weighted (<span class="math inline">\(p\)</span>) arithmetic average of outcomes <span class="math inline">\(x_1\)</span> (<code>TRUE</code>) and <span class="math inline">\(x_2\)</span> (<code>FALSE</code>),</p>
<!-- TODO use pretty math (doesn't work with with tufte-html for now) -->
<!-- <script type="text/x-mathjax-config"> -->
<!-- MathJax.Hub.Config({ -->
<!--   TeX: { equationNumbers: { autoNumber: "AMS" } } -->
<!-- }); -->
<!-- </script> -->
<!-- \begin{equation} -->
<!--   \mathbb{E}(X) = x_1 p_1 + x_2 p_2 \label{eq:ev} -->
<!-- \end{equation} -->
<p><span class="math display">\[\mathbb{E}(X) = x_1 p_1 + x_2 p_2\]</span></p>
<p>where <span class="math inline">\(p_1\)</span> probability of <code>TRUE</code> is simply the count of <code>TRUE</code>s <span class="math inline">\(z\)</span> divided by the number of items <span class="math inline">\(y\)</span>, <span class="math inline">\(p_1 = z / y\)</span>, and <span class="math inline">\(p_2 = 1 - p_1\)</span>. We then subtract this <em>expected value</em> from the <em>observed</em> realization for some <span class="math inline">\(x\)</span>, yielding</p>
<p><span class="math display">\[x{'} = x - \mathbb{E}(X).\]</span></p>
<p>We can now express <code>Julius</code>‘above assignments from table @ref(tab:ass-example) as <span class="math inline">\(x{'}\)</span>, an information-theoretical <em>surprisal value</em> <span class="citation">(Attneave 1959)</span>.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> A high positive value, such <code>Julius</code>’ value for category <code>1</code> on <code>language-of-bees</code> indicates that this assignment is <em>positively</em> surprising, given the probable assignment; it’s <code>TRUE</code>“ishness” is <em>higher</em> than would be expected on average. The inverse holds for <code>Julius</code>’ value for category <code>2</code> on <code>eating-grandpa</code>; it is <em>less</em> <code>TRUE</code>ish than would be expected, even though only slightly so.</p>
<p>Summary statistics about the surprisal value matrices are also readily interpretable. For example, <code>Julius</code> has a mean surprisal value of <code><a href="https://rdrr.io/r/base/mean.html">mean(surprise$Julius["language-of-bees", ])</a></code> for <code>language-of-bees</code>, implying that the item attracted many <em>more</em> category assignments than expected. Conversely, a high standard deviation, such as for <code>Julius</code>’ <code>the-same</code> (<code><a href="https://rdrr.io/r/stats/sd.html">sd(surprise$Julius["the-same", ])</a></code>) suggests that the item was assigned much <em>more</em> than expected to some categories, but not to others. Both characteristics of category assignments are appropriately standardized away by the correlation coefficient, because a high center of, or high spread of assignments should not give extra weight to some item. <!-- TODO this is still a little thin, but also maybe just a footnote --></p>
<p>Thus standardized for the category <em>width</em>, <em>spread</em> and <em>center</em> we can now easily <em>correlate</em> the surprisal value of all item pairs, yielding a three dimensional array of items x items x people.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></p>
<p>This correlation of the <em>surprisal values</em> of item pairs, observed over a (varying) number of (open-ended) categories is, oddly, neither an <code>R</code>, nor a <code>Q</code>-type analysis. The correlated variables are items, but the observations are <em>also</em> “variables” of sorts, namely the inductive categories described by participants. As will be obvious in the next step, this preliminary summary is necessary to enable a “Q-way” analysis of the categorical data available here: categorisations must <em>first</em> be made comparable accross participants, which is what the surprisal value correlation matrices as a rough indication of <em>categorically</em> assigned similarity accomplish.</p>
<p><code>Julius</code> slice is display in figure @ref(fig:make-cora). The correlation coefficients encompass a surprising range, all the way from <code>-1</code> to <code>1</code> - even on the off-diagonal. Strictly speaking, the values <em>can</em> be interpreted as categorically assigned, <em>surprising</em> similarity. <em>Measured by the granularity of the present study</em> (i.e. the number of observed categories for some participant), an off-diagonal <code>1</code> can be taken to indicate <em>total</em> similarity. As with other samples, this measure entails an element of chance: <code>Julius</code>’ <em>perfect</em> correlation between items <code>resistance</code> and <code>comma</code> likely does <em>not</em> indicate that <code>Julius</code> thought the two were truly <em>identical</em>. They just <em>appear</em> to be identical on the (limited) number categories observed, and would probably be differentiated, had they been observed on more, or different categories. We can, consequently, have more confidence in a surprisal correlation matrix that is based on a greater number of observation (= categories), because chance “identities” are less likely to arise, though given the intensive nature of the method, the number of observations is likely to always remain quite limited. When extracting the <em>shared</em> patterns of categorical similarity, it will be important to deflate resulting models by the probability of such random, likely false-positive identities through means of a custom parallel analysis or related methods <span class="citation">(Glorfeld 1995, <span class="citation">Horn (1965)</span>)</span>.</p>
<p>This operation appears, at first glance, similar to Repertory Grid Technique <span class="citation">(RGT, e.g. Fransella, Bell, and Bannister 2004)</span>, where participants also evaluate a <em>given</em> set of items (called “elements” in RGT) on some inductive, participant-defined categories (called “constructs” in RGT), though RGT employs <em>interval</em> measurements (not categorical) and cannot reveal inter-individual <em>differences</em>, because the analysis procceeds R-ways. The analysis suggested here, works quite differently - observations and variables are, in classic Q fashion, transposed. Whereas in RGT, open-ended <em>categories</em> are correlated over <em>items</em> as observations to reveal similarity categories, we - initially - suggest to correelate <em>items</em> over categories as observations to reveal similar items, which are, at a later stage, referred back to initially entered categories.</p>
<p>The correlation heatmap in @ref(fig:make-cora) is broadly informative, but too big for researchers to make sense of, simply because the item combinations are many - as they should be, for a productive analysis. Because item surprisal similarity is here expressed as a simple correlation matrix, we can employ a Principal Components Analysis (PCA) to reduce its dimensionality.</p>
<p>Figure @ref(fig:julius-pca) displays the item loadings in the first two rotated principal components (out of seven with an Eigenvalue greater than one). These loadings can be interpreted as similarity of items in terms of their surprising category assignment; <code>i-we</code> and <code>but-how</code> <em>both</em> are surprisingly <em>present</em> on the first dimension of such similarity, while <code>riddle</code> and <code>idiom</code> are both surprisingly <em>absent</em> on the same dimension. Using factor <em>scores</em>, which are here ideal-typical category <em>assignments</em>, we can also relate this summary back to the original descriptions. A cursory inspection of the item pattern and the underlying descriptions suggests that <code>Julius</code> first rotated reflects his formal categorisations (such as punctuation), as opposed to his more substantive judgments (such as whether an item was a joke, or played with the meaning of words). Such <em>individual</em> level summary illustrates the logic and <em>should</em> be meaningful, in principle, though it is likely to be of limited use in real research because the underlying observations are so sparse, and uncorrected surprisal values accordingly unreliable for an individual.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
</div>
<div id="analysis-2-ideal-types-of-ideal-types" class="section level2">
<h2 class="hasAnchor">
<a href="#analysis-2-ideal-types-of-ideal-types" class="anchor"></a>Analysis 2: Ideal Types of Ideal Types</h2>
<p>We now have an array <span class="math inline">\(\underline{X}\)</span> of order</p>
<p><span class="math display">\[J \times J \times K\]</span></p>
<p>or, in this context,</p>
<p><span class="math display">\[Items \times Items \times People\]</span>,</p>
<p>where cells cells are Pearson’s correlation coefficients, each across some observations of some item pair. (See <a href="http://stats.stackexchange.com/questions/230479/how-to-reduce-the-dimensionality-of-a-similarity-matrix-of-categorical-co-occur/231333#231333">this related answer</a> on why this correlation matrix is the only comparable data we have; we can’t go back to raw<em>er</em> data.)</p>
<p>Since <em>both</em> the number of people <em>and</em> the number of item-pairs are too large to make sense of the data, we need to reduce the dimensionality. Specifically, we want to reduce the people to <em>fewer</em> ideal types, and then describe these ideal type’s <em>ideal types</em> of co-occuring items, potentially yielding of shared, categorical subjectivities of participants.</p>
<p>Since we are looking for a simple dimensionality reduction (not a causal or latent variable model), the n-mode generalisations of PCA, Candecomp/Parafac <span class="citation">(PC, Carrol and Chang 1970 and independently <span class="citation">Harshman (1970)</span>)</span> and the more involved Tucker procedures <span class="citation">(Tucker 1966)</span> apply here.</p>
</div>
<div id="open-issues" class="section level2">
<h2 class="hasAnchor">
<a href="#open-issues" class="anchor"></a>Open issues</h2>
<ul>
<li>rotation?</li>
<li>pre-proccessing (centering, scaling)</li>
<li>post-processing (normalizing)</li>
<li>robustness and Bayesian critique (parallel analysis)</li>
</ul>
</div>
<div id="interpretation" class="section level2">
<h2 class="hasAnchor">
<a href="#interpretation" class="anchor"></a>Interpretation</h2>
<p>While different in procedure and data type, <code>Q-Cat</code> shares the paradigmatic foundations of Q methodology. As Watts writes about Q-<em>Sorts</em>, here <em>too</em>:</p>
<blockquote>
<p>“Subjectivity is not a mental entity. It does not reflect any inner experience and it has little in common with concepts like mind and consciousness.”</p>
<p>– Simon Watts <span class="citation">(2011, 40)</span></p>
</blockquote>
<!-- "Operational definitions begin with concepts in search of behavior; operant definitions begin with behavior in search of concepts." [@Brown-1980, p. 28] -->
<!-- This is an extension of the scientific study of human subjectivity. -->
<!-- this is not about mental representation as from psych, but -->
<!-- -a viewpoint is relational: an interaction between subject and world (an object, another person, an event, a concept ... ) -->
<!-- -viewpoints are the act of observation -->
<!-- -viewpoints are inherently meaningful -->
<!-- ## Categorizing -->
<!-- Relevance: seeing the world efficiently through categories -->
<!-- Q-Sorting is a special case of categorization in general [@coxon-1999] -->
<!-- ## Categorizing and Subjectivity -->
<!-- Do the theory of viewpoints in operant subjectivity apply as well in categorization? -->
<!--    "A viewpoint does not exist within a person, but only in their current outlook or positioning relative to some aspect of their immediate environment (a circumstance perhaps, an event, or some other object of enquiry). A viewpoint exists and takes a defined form only in the moment of relationship between a subject and its object, between knower and known, observer and observed. Given this essentially relational nature, a viewpoint could never be described as belonging to a person in any enduring sense, nor could it even be made meaningful by reference to them alone." [@watts-2011, p. 40] -->
<!-- -a viewpoint is judgmental, means neither right nor wrong -->
<!--    "In the first place, a subjective operant, unlike a scale response, is neither right nor wrong." [@Brown-1980, p. 4] -->
<!-- -a viewpoint is the first-person perspective -->
<!--    "[...] it is of more scientific interest to know how subjects have combined items (e.g., as in Q sorting) than how subjects have responded to a set of items combined a priori by the investigator." [@Brown-1980, p. 21] -->
<!--    "Operational definitions begin with concepts in search of behavior; operant definitions begin with behavior in search of concepts." [@Brown-1980, p. 28] -->
<!-- -viewpoints are "categories of thinking" -->
<!-- ##Theory of Categorization -->
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-attneave-1959">
<p>Attneave, Fred. 1959. <em>Applications of Information Theory to Psychology: A Summary of Basic Concepts, Methods, and Results</em>. New York: Henry Holt.</p>
</div>
<div id="ref-Brown1980">
<p>Brown, Steven R. 1980. <em>Political Subjectivity: Applications of Q Methodology in Political Science</em>. New Haven, CT: Yale University Press.</p>
</div>
<div id="ref-burton-1972">
<p>Burton, Michael. 1972. “Semantic Dimensions of Occupation Names.” <em>Multidimensional Scaling: Applications in the Behavioral Sciences</em> 2: 55–72.</p>
</div>
<div id="ref-carrol-chang-1970">
<p>Carrol, JD, and JJ Chang. 1970. “Analysis of Individual Differences in Multidimensional Scaling via an N-Way Generalization of Eckart-Young Decomposition.” <em>Psychometrika</em> 35: 283–319.</p>
</div>
<div id="ref-coxon-1999">
<p>Coxon, Anthony Peter Macmillan. 1999. <em>Sorting Data: Collection and Analysis</em>. Vol. 127. Los Angeles: Sage Publications.</p>
</div>
<div id="ref-fransella-2004">
<p>Fransella, Fay, Richard Bell, and Don Bannister. 2004. <em>A Manual for Repertory Grid Technique</em>. Hoboken: John Wiley and Sons.</p>
</div>
<div id="ref-Glorfeld-1995">
<p>Glorfeld, Louis W. 1995. “An Improvement on Horn’s Parallel Analysis Methodology for Selecting the Correct Number of Factors to Retain.” <em>Educational Psychological Measurement</em> 55 (3): 377–93.</p>
</div>
<div id="ref-harshman-1970">
<p>Harshman, Richard A. 1970. “Foundations of the Parafac Procedure: Models and Conditions for an ’Explanatory’ Multimodal Factor Analysis.” UCLA Working Papers in Phonetics. Los Angeles, CA: University of California, Los Angeles.</p>
</div>
<div id="ref-Horn-1965">
<p>Horn, John L. 1965. “A Rationale and Test for the Number of Factors in Factor Analysis.” <em>Psychometrica</em> 30 (2): 179–85.</p>
</div>
<div id="ref-rosch-1978">
<p>Rosch, Eleanor. 1978. “Principles of Categorization. Cognition and Categorization, Ed. by Eleanor Rosch &amp; Barbara B. Lloyd, 27-48.”</p>
</div>
<div id="ref-Tucker-1966">
<p>Tucker, Ledyard R. 1966. “Some Mathematical Notes on Three-Mode Factor Analysis.” <em>Psychometrika</em> 31 (3).</p>
</div>
<div id="ref-watts2011subjectivity">
<p>Watts, Simon. 2011. “Subjectivity as Operant: A Conceptual Exploration and Discussion.” <em>Operant Subjectivity: The International Journal of Q Methodology</em> 35 (1): 37–47.</p>
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>In a future iteration, participants will ipsatively <em>rank</em> items vis-a-vis a categorical <em>prototype</em> (chosen from the items, compare <span class="citation">Rosch (1978)</span>), yielding <em>ordinal</em> information, requiring a separate, non-parametric analytical procedure.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>The comparison is a bit unfair, because LOS produces a lot more information then a Q-sort.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>This canonical data representation can be easily produced from conveniently entered raw data with <a href="http://www.maxheld.de/pensieve"><code>pensieve::import_qcat()</code></a>.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Note that the data in canonical form <em>cannot</em> be compared between individuals. For example, <code>Nhome</code>’s first category is independently defined (by her) from the above <code>Julius</code>’s first category, and so on.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Our measure is a greatly simplified version of <em>Burton’s <span class="math inline">\(Z\)</span></em>, which required <em>conditional</em> probabilities for item-pair co-occurences, because items are drawn into MECE categories <em>without</em> replacement <span class="citation">(compare Burton 1972)</span>.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>A simpler approach, tried out earlier, would simply <em>count</em> the co-occurences of item-pairs in any set of categories, but such a procedure does not standardize for category width, and has the disadvantage of only producing a <em>co-occurence</em> matrix.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>A proper analysis of individual level categorisations will also benefit from more specialized visualizations and may require custom rotation methods.<a href="#fnref7">↩</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#sorting-procedure">Sorting Procedure</a></li>
      <li>
<a href="#data-storage">Data Storage</a><ul class="nav nav-pills nav-stacked">
<li><a href="#analysis-1-shared-categories-as-surprising-similarity">Analysis 1: Shared Categories as Surprising Similarity</a></li>
      <li><a href="#analysis-2-ideal-types-of-ideal-types">Analysis 2: Ideal Types of Ideal Types</a></li>
      <li><a href="#open-issues">Open issues</a></li>
      <li><a href="#interpretation">Interpretation</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Max Held.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: '3cb428b0eb896bffce7bf64509cf7054',
    indexName: 'pensieve',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
